{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:01:52.317562Z",
     "start_time": "2019-05-16T13:01:52.313097Z"
    }
   },
   "outputs": [],
   "source": [
    "#提取tf-idf特征\n",
    "#语料库\n",
    "corpus = [\n",
    "    'this is the first document',\n",
    "    'this is the second second document',\n",
    "    'and the third one',\n",
    "    'is this the first document'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:02:00.099697Z",
     "start_time": "2019-05-16T13:02:00.095730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'the', 'first', 'document'], ['this', 'is', 'the', 'second', 'second', 'document'], ['and', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'document']]\n"
     ]
    }
   ],
   "source": [
    "#分词\n",
    "word_list = []\n",
    "for i in range(len(corpus)):\n",
    "    word_list.append(corpus[i].split(' '))\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:02:58.519298Z",
     "start_time": "2019-05-16T13:02:56.566747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)], [(0, 1), (2, 1), (3, 1), (4, 1), (5, 2)], [(3, 1), (6, 1), (7, 1), (8, 1)], [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#使用gensim提取tf-idf\n",
    "from gensim import corpora\n",
    "# 赋给语料库中每个词(不重复的词)一个整数id\n",
    "dictionary = corpora.Dictionary(word_list)\n",
    "new_corpus = [dictionary.doc2bow(text) for text in word_list]\n",
    "# 元组中第一个元素是词语在词典中对应的id，第二个元素是词语在文档中出现的次数\n",
    "print(new_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:03:36.949112Z",
     "start_time": "2019-05-16T13:03:36.944648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': 0, 'first': 1, 'is': 2, 'the': 3, 'this': 4, 'second': 5, 'and': 6, 'one': 7, 'third': 8}\n"
     ]
    }
   ],
   "source": [
    " # 通过下面的方法可以看到语料库中每个词对应的id\n",
    " print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:03:56.566632Z",
     "start_time": "2019-05-16T13:03:56.548280Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练模型并保存\n",
    "from gensim import models\n",
    "tfidf = models.TfidfModel(new_corpus)\n",
    "tfidf.save(\"my_model.tfidf\")\n",
    "\n",
    "# 载入模型\n",
    "tfidf = models.TfidfModel.load(\"my_model.tfidf\")\n",
    "\n",
    "# 使用这个训练好的模型得到单词的tfidf值\n",
    "tfidf_vec = []\n",
    "for i in range(len(corpus)):\n",
    "    string = corpus[i]\n",
    "    string_bow = dictionary.doc2bow(string.lower().split())\n",
    "    string_tfidf = tfidf[string_bow]\n",
    "    tfidf_vec.append(string_tfidf)\n",
    "print(tfidf_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论\n",
    "\n",
    "gensim训练出来的tf-idf值左边是词的id，右边是词的tfidf值  \n",
    "gensim有自动去除停用词的功能，比如the    \n",
    "gensim会自动去除单个字母，比如i  \n",
    "gensim会去除没有被训练到的词，比如name  \n",
    "所以通过gensim并不能计算每个单词的tfidf值  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:08:53.202634Z",
     "start_time": "2019-05-16T13:08:53.071507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
      "[[0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
      "  0.35872874 0.         0.43877674]\n",
      " [0.         0.27230147 0.         0.27230147 0.         0.85322574\n",
      "  0.22262429 0.         0.27230147]\n",
      " [0.55280532 0.         0.         0.         0.55280532 0.\n",
      "  0.28847675 0.55280532 0.        ]\n",
      " [0.         0.43877674 0.54197657 0.43877674 0.         0.\n",
      "  0.35872874 0.         0.43877674]]\n"
     ]
    }
   ],
   "source": [
    "#sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "# 得到语料库所有不重复的词\n",
    "print(tfidf_vec.get_feature_names())\n",
    "\n",
    "# 得到每个单词对应的id值\n",
    "print(tfidf_vec.vocabulary_)\n",
    "\n",
    "# 得到每个句子所对应的向量\n",
    "# 向量里数字的顺序是按照词语的id顺序来的\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:18:00.301999Z",
     "start_time": "2019-05-16T13:18:00.288628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'this': 1, 'is': 1, 'the': 1, 'first': 1, 'document': 1}),\n",
       " Counter({'this': 1, 'is': 1, 'the': 1, 'second': 2, 'document': 1}),\n",
       " Counter({'and': 1, 'the': 1, 'third': 1, 'one': 1}),\n",
       " Counter({'is': 1, 'this': 1, 'the': 1, 'first': 1, 'document': 1})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#直接用python\n",
    "#统计词频\n",
    "from collections import Counter\n",
    "countlist = []\n",
    "for i in range(len(word_list)):\n",
    "    count = Counter(word_list[i])\n",
    "    countlist.append(count)\n",
    "countlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:18:19.924444Z",
     "start_time": "2019-05-16T13:18:19.918988Z"
    }
   },
   "outputs": [],
   "source": [
    "# word可以通过count得到，count可以通过countlist得到\n",
    "\n",
    "# count[word]可以得到每个单词的词频， sum(count.values())得到整个句子的单词总数\n",
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())\n",
    "\n",
    "# 统计的是含有该单词的句子数\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)\n",
    " \n",
    "# len(count_list)是指句子的总数，n_containing(word, count_list)是指含有该单词的句子的总数，加1是为了防止分母为0\n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list) / (1 + n_containing(word, count_list)))\n",
    "\n",
    "# 将tf和idf相乘\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:18:32.757132Z",
     "start_time": "2019-05-16T13:18:32.751208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1\n",
      "\tWord: first, TF-IDF: 0.05754\n",
      "\tWord: this, TF-IDF: 0.0\n",
      "\tWord: is, TF-IDF: 0.0\n",
      "\tWord: document, TF-IDF: 0.0\n",
      "\tWord: the, TF-IDF: -0.04463\n",
      "Top words in document 2\n",
      "\tWord: second, TF-IDF: 0.23105\n",
      "\tWord: this, TF-IDF: 0.0\n",
      "\tWord: is, TF-IDF: 0.0\n",
      "\tWord: document, TF-IDF: 0.0\n",
      "\tWord: the, TF-IDF: -0.03719\n",
      "Top words in document 3\n",
      "\tWord: and, TF-IDF: 0.17329\n",
      "\tWord: third, TF-IDF: 0.17329\n",
      "\tWord: one, TF-IDF: 0.17329\n",
      "\tWord: the, TF-IDF: -0.05579\n",
      "Top words in document 4\n",
      "\tWord: first, TF-IDF: 0.05754\n",
      "\tWord: is, TF-IDF: 0.0\n",
      "\tWord: this, TF-IDF: 0.0\n",
      "\tWord: document, TF-IDF: 0.0\n",
      "\tWord: the, TF-IDF: -0.04463\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for i, count in enumerate(countlist):\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: tfidf(word, count, countlist) for word in count}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算互信息\n",
    "#x为特征，y为预测biao'qian\n",
    "from sklearn import metrics as mr\n",
    "mr.mutual_info_score(label,x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
